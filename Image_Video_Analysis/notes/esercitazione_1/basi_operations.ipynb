{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToPILImage()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "transforms.ToTensor()   # to torch tensor\n",
    "transforms.ToPILImage() # to pil\n",
    "#np.array()             # to numpy array\n",
    "\n",
    "\n",
    "#Image.open(#path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image = np.random.randint(0,255,size=(100,100),dtype=np.float32)\n",
    "random_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transforms.ToPILImage()(random_image)) # dominio tra [0,255]\n",
    "print(transforms.To(random_image).size)      # dominio tra [0,1]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset che indica come sono acceduti i dati\n",
    "  - transform : applica una trasformazione indicata in torchvision (clipping ecc..)\n",
    "  - target_transform: \n",
    "  - per ogni label vi è una cartella con tutti gli elementi di quella label. Il tutto nella cartella root\n",
    "  - \n",
    "- Dataloader che gestisce il batch, shuffling ecc..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.cat $\\rightarrow$ concatena i tensori lungo la dimensione indicata\n",
    "\n",
    "clamp(0,0,1.0) $\\rightarrow$ clip between 0 and 1\n",
    "\n",
    "pytorch: con _ l'operazione è inplace, senza è fatto su una copia\n",
    "\n",
    "zip: prende l'i-esimo elemento per ogni lista passata come argomento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "a= torch.rand(1,100,100) # dominio tra [0,1]\n",
    "b= torch.rand(1,100,100)\n",
    "c= torch.rand(1,100,100)\n",
    "\n",
    "d = torch.cat((a,b,c),dim=0)\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 7, 9)\n",
      "(2, 5, 8, 10)\n"
     ]
    }
   ],
   "source": [
    "for a  in zip((1,2,3),(4,5,6),(7,8),(9,10,11)):\n",
    "    print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
